import torch
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification

# ìºì‹œì— ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œ (ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ì‚¬ìš©)
model_name = "distilbert/distilbert-base-uncased-finetuned-sst-2-english"  # ì—¬ê¸°ì— ì›í•˜ëŠ” ëª¨ë¸ëª…ì„ ì…ë ¥

tokenizer = DistilBertTokenizer.from_pretrained(model_name, local_files_only=True)
model = DistilBertForSequenceClassification.from_pretrained(model_name, local_files_only=True)

print("ë¡œì»¬ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")


# ì…ë ¥ ë¬¸ì¥
text = "I love this product! It's amazing."

# í† í°í™” (PyTorch í…ì„œ ë³€í™˜)
inputs = tokenizer(text, return_tensors="pt")

# ëª¨ë¸ ì¶”ë¡  (GPU ì‚¬ìš© ê°€ëŠ¥)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device) # gpu (ë˜ëŠ” cpu) ë¡œ ì´ë™

with torch.no_grad():
    outputs = model(**{k: v.to(device) for k, v in inputs.items()})
    
# ê²°ê³¼ í•´ì„
logits = outputs.logits

predicted_class_id = logits.argmax().item()
predicted_label = model.config.id2label[predicted_class_id]  # ëª¨ë¸ì—ì„œ ì§ì ‘ ë¼ë²¨ ë§¤í•‘ ê°€ì ¸ì˜¤ê¸°

# ê°ì„± ë¼ë²¨ ë§¤í•‘
print(f"ğŸ“¢ ì…ë ¥: {text} â†’ ğŸ¯ ì˜ˆì¸¡: {predicted_label}")
