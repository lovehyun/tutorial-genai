import os
import faiss
from sentence_transformers import SentenceTransformer
from openai import OpenAI
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (OpenAI API í‚¤)
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ê²½ê³  ì œê±° (OpenMP ì¶©ëŒ í•´ê²°)
# os.environ["USE_SIMPLE_THREADED_LEVEL3"] = "1"
# os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"

# ì„ë² ë”© ëª¨ë¸ (L2 ê±°ë¦¬ ê¸°ë°˜ì—ì„œë„ ë™ì¼í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥)
embedding_model = SentenceTransformer("all-mpnet-base-v2")

# ë¬¸ì„œ ë°ì´í„° (FAISSì— ì €ì¥í•  ë°ì´í„°)
documents = [
    "Pythonì€ ê°•ë ¥í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
    "OpenAIëŠ” AI ì—°êµ¬ë¥¼ ì„ ë„í•˜ëŠ” ê¸°ì—…ì…ë‹ˆë‹¤.",
    "FAISSëŠ” ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
]

# ë¬¸ì„œ ì„ë² ë”© ìƒì„± (ì •ê·œí™” ì œê±°!)
doc_embeddings = embedding_model.encode(documents)  # ì›ë³¸ ë²¡í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©

# FAISS ì¸ë±ìŠ¤ ìƒì„± (L2 ê±°ë¦¬ ê¸°ë°˜)
embedding_dim = doc_embeddings.shape[1]
index = faiss.IndexFlatL2(embedding_dim)  # L2 ê±°ë¦¬ ê¸°ë°˜ ì¸ë±ìŠ¤
index.add(doc_embeddings)  # FAISSì— ë²¡í„° ì¶”ê°€

# ê²€ìƒ‰ + OpenAI API í™œìš©í•œ ì‘ë‹µ ìƒì„± í•¨ìˆ˜
def rag_query(user_query):
    # ë¡œì»¬ì—ì„œ ì„ë² ë”© ë³€í™˜ (ì •ê·œí™” ì œê±°!)
    query_embedding = embedding_model.encode([user_query])  # ì›ë³¸ ë²¡í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©

    # FAISS ê²€ìƒ‰ (ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œ ì°¾ê¸°)
    distances, indices = index.search(query_embedding, k=1)  # L2 ê±°ë¦¬ ê¸°ë°˜ ê²€ìƒ‰
    retrieved_doc = documents[indices[0][0]]

    # L2 ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„ ë³€í™˜ ë°©ì‹ (0~1ë¡œ ë³€í™˜)
    similarity_score = 1 / (1 + distances[0][0])  # ê±°ë¦¬ê°’ì„ 0~1 ì‚¬ì´ë¡œ ë³€í™˜

    print("\nğŸ” FAISS ê²€ìƒ‰ ê²°ê³¼:")
    print(f"   ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ: {retrieved_doc}")
    print(f"   ğŸ¯ ê²€ìƒ‰ ì •í™•ë„(ìœ ì‚¬ë„ ì ìˆ˜): {similarity_score:.4f}")

    # OpenAI APIë¥¼ í™œìš©í•œ ìµœì¢… ì‘ë‹µ ìƒì„±
    prompt = f"""
    ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œë§Œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.
    ì¶”ê°€ì ì¸ ì§€ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì œê³µëœ ì •ë³´ ë‚´ì—ì„œë§Œ ë‹µë³€í•˜ì„¸ìš”.

    ì°¸ê³  ì •ë³´:
    {retrieved_doc}

    ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_query}
    ë‹µë³€:
    """

    print("\nğŸ“ OpenAI APIì—ê²Œ ì „ë‹¬ëœ í”„ë¡¬í”„íŠ¸:")
    print(prompt)

    response = client.chat.completions.create(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì œê³µëœ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."},
            {"role": "user", "content": prompt},
        ]
    )

    return response.choices[0].message.content

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
query = "OpenAIëŠ” ì–´ë–¤ ê¸°ì—…ì¸ê°€ìš”?"
print("\nğŸ’¬ GPT ì‘ë‹µ:\n", rag_query(query))
