# pip install openai faiss-cpu python-dotenv

import os
import numpy as np
import faiss
from openai import OpenAI
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI API í‚¤ ì„¤ì •
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ì˜ˆì œ ë¬¸ì„œ ë°ì´í„° (RAGë¥¼ ìœ„í•œ ê²€ìƒ‰ ëŒ€ìƒ)
documents = [
    "Pythonì€ ê°•ë ¥í•œ í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì…ë‹ˆë‹¤.",
    "OpenAIëŠ” AI ì—°êµ¬ë¥¼ ì„ ë„í•˜ëŠ” ê¸°ì—…ì…ë‹ˆë‹¤.",
    "FAISSëŠ” ë²¡í„° ê²€ìƒ‰ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤.",
]

# ë¬¸ì„œ ì¸ë±ì‹± (ë²¡í„° ìƒì„± ë° ì €ì¥)
def get_embedding(text):
    response = client.embeddings.create(input=text,
    model="text-embedding-ada-002")
    return np.array(response.data[0].embedding)

# ë¬¸ì„œ ì„ë² ë”© ìƒì„± ë° ë²¡í„°DB(Faiss) êµ¬ì¶•
index = faiss.IndexFlatL2(1536)  # OpenAI ì„ë² ë”© ì°¨ì›(1536)
doc_embeddings = np.array([get_embedding(doc) for doc in documents])
index.add(doc_embeddings)

# ê²€ìƒ‰ ë° RAG ê¸°ë°˜ ì‘ë‹µ ìƒì„±
def rag_query(user_query):
    query_embedding = get_embedding(user_query)
    _, indices = index.search(np.array([query_embedding]), k=1)  # ê°€ì¥ ê°€ê¹Œìš´ ë¬¸ì„œ ê²€ìƒ‰
    retrieved_doc = documents[indices[0][0]]  # ê²€ìƒ‰ëœ ë¬¸ì„œ
    
    # print(f"\nğŸ” FAISS ê²€ìƒ‰ëœ ë¬¸ì„œ:\n{retrieved_doc}\n")  # ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶œë ¥

    prompt = f"""
    {retrieved_doc}
    
    ì‚¬ìš©ìì˜ ì§ˆë¬¸: {user_query}
    ë‹µë³€:
    """

    response = client.chat.completions.create(model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë„ìš°ë¯¸ì…ë‹ˆë‹¤."},
        # {"role": "system", "content": "ë‹¹ì‹ ì€ ì œê³µëœ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤."},
        {"role": "user", "content": prompt}
    ])

    return response.choices[0].message.content

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
query = "OpenAIëŠ” ì–´ë–¤ ê¸°ì—…ì¸ê°€ìš”?"
print(rag_query(query))
